import faiss
import pickle
import numpy as np
from pathlib import Path
from config import (
    FAISS_INDEX_PATH, 
    FAISS_METADATA_PATH,
    TOP_K,
    USE_SIMILARITY_THRESHOLD,
    SIMILARITY_THRESHOLD
)
import logging

logger = logging.getLogger(__name__)

class FAISSVectorStore:
    def __init__(self):
        self.index = None
        self.metadata = []
        self.embedding_dimension = None
    
    def create_index(self, embeddings: np.ndarray, metadata: list):
        """
        T·∫°o FAISS index t·ª´ embeddings
        """
        logger.info("üî® T·∫†O FAISS INDEX")
        logger.info(f"   Embeddings shape: {embeddings.shape}")
        
        try:
            # ƒê·∫£m b·∫£o embeddings l√† float32
            embeddings = embeddings.astype(np.float32)
            self.embedding_dimension = embeddings.shape[1]
            
            # T·∫°o index (L2 distance - cosine similarity)
            self.index = faiss.IndexFlatIP(self.embedding_dimension)
            self.index.add(embeddings)
            
            self.metadata = metadata
            
            logger.info(f"‚úÖ Index t·∫°o th√†nh c√¥ng: {self.index.ntotal} vectors\n")
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o index: {str(e)}")
            raise
    
    def save(self):
        """L∆∞u index v√† metadata"""
        logger.info("üíæ L∆ØU FAISS INDEX")
        
        try:
            Path(FAISS_INDEX_PATH).parent.mkdir(parents=True, exist_ok=True)
            
            faiss.write_index(self.index, FAISS_INDEX_PATH)
            with open(FAISS_METADATA_PATH, 'wb') as f:
                pickle.dump(self.metadata, f)
            
            logger.info(f"   Index: {FAISS_INDEX_PATH}")
            logger.info(f"   Metadata: {FAISS_METADATA_PATH}")
            logger.info("‚úÖ L∆∞u th√†nh c√¥ng\n")
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói l∆∞u: {str(e)}")
            raise
    
    def load(self):
        """Load index t·ª´ disk"""
        logger.info("üìÇ LOAD FAISS INDEX")
        
        try:
            if not Path(FAISS_INDEX_PATH).exists():
                raise FileNotFoundError(f"Index kh√¥ng t·ªìn t·∫°i: {FAISS_INDEX_PATH}")
            
            self.index = faiss.read_index(FAISS_INDEX_PATH)
            with open(FAISS_METADATA_PATH, 'rb') as f:
                self.metadata = pickle.load(f)
            
            self.embedding_dimension = self.index.d
            
            logger.info(f"   Vectors: {self.index.ntotal}")
            logger.info(f"   Dimension: {self.embedding_dimension}")
            logger.info("‚úÖ Load th√†nh c√¥ng\n")
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói load: {str(e)}")
            raise
    
    def search(self, query_embedding: np.ndarray, k: int = TOP_K) -> list:
        """
        Semantic search v·ªõi FAISS
        Tr·∫£ v·ªÅ top K results v·ªõi similarity score
        """
        try:
            query_embedding = query_embedding.astype(np.float32).reshape(1, -1)
            
            # FAISS t√≠nh L2 distance, ta chuy·ªÉn sang cosine similarity
            distances, indices = self.index.search(query_embedding, k)
            
            results = []
            for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):
                similarity = float(distance)   
                
                # B·∫≠t/t·∫Øt threshold
                if USE_SIMILARITY_THRESHOLD and similarity < SIMILARITY_THRESHOLD:
                    continue
                
                results.append({
                    "rank": i + 1,
                    "content": self.metadata[idx]["content"],
                    "metadata": self.metadata[idx]["metadata"],
                    "similarity": round(similarity, 4),
                    "distance": round(distance, 4)
                })
            
            return results
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói search: {str(e)}")
            raise
