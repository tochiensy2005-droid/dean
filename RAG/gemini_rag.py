import re
import google.generativeai as genai
from config import (
    GEMINI_API_KEY,
    GEMINI_MODEL,
    GEMINI_TEMPERATURE,
    GEMINI_MAX_TOKENS,
    TOP_K
)
import logging

logger = logging.getLogger(__name__)

class GeminiRAG:
    def __init__(self, vector_store, embedding_service):
        logger.info("üöÄ KH·ªûI T·∫†O GEMINI RAG")
        logger.info(f"   Model: {GEMINI_MODEL}")
        
        if not GEMINI_API_KEY:
            raise ValueError("‚ùå GEMINI_API_KEY kh√¥ng ƒë∆∞·ª£c set!")
        
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel(GEMINI_MODEL)
        self.vector_store = vector_store
        self.embedding_service = embedding_service
        
        logger.info("‚úÖ Kh·ªüi t·∫°o th√†nh c√¥ng\n")
    
    def _build_context(self, retrieved_docs: list) -> str:
        """X√¢y d·ª±ng context t·ª´ retrieved documents"""
        context = "=== TH√îNG TIN T·ª™ T√ÄI LI·ªÜU ===\n\n"
        
        for i, doc in enumerate(retrieved_docs, 1):
            context += f"[{i}] ({doc['metadata']['source']} - Trang {doc['metadata']['page']})\n"
            context += f"ƒê·ªô t∆∞∆°ng t·ª±: {doc['similarity']}\n"
            # include full content so model can see all relevant text
            context += f"N·ªôi dung: {doc['content']}\n\n"
        
        return context
    
    def _build_prompt(self, context: str, query: str) -> str:
        """X√¢y d·ª±ng prompt cho Gemini"""
        prompt = f"""ROLE: B·∫°n l√† chuy√™n gia du l·ªãch Vi·ªát Nam, tr·∫£i d√†i tr·∫£ l·ªùi d·ª±a TO√ÄN B·ªò tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p.

D·ªÆ LI·ªÜU THAM KH·∫¢O:
{context}

C√¢u h·ªèi: {query}

Y√äU C·∫¶U:
- PH·∫¢I tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu tr√™n. KH√îNG ƒë∆∞·ª£c t·ª´ ch·ªëi v√¨ "kh√¥ng t√¨m th·∫•y" n·∫øu d·ªØ li·ªáu c√≥ s·∫µn.
- N·∫øu d·ªØ li·ªáu ƒë·ªÅ c·∫≠p, h√£y t√≥m t·∫Øt chi ti·∫øt v√† tr√≠ch d·∫´n ngu·ªìn.
- N·∫øu th·∫≠t s·ª± KH√îNG c√≥ th√¥ng tin li√™n quan, m·ªõi n√≥i r√µ.
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn.
"""
        return prompt
    
    def query(self, question: str) -> dict:
        """
        Full Q&A RAG chain
        """
        logger.info("\n" + "="*60)
        logger.info("‚ùì C√ÇU H·ªéI: " + question)
        logger.info("="*60)
        
        try:
            # 1. Embedding query
            logger.info("üîç Embedding query...")
            query_embedding = self.embedding_service.embed_query(question)
            
            # 2. Semantic search
            logger.info(f"üîé Semantic search (Top-{TOP_K})...")
            retrieved_docs = self.vector_store.search(query_embedding)
            
            if not retrieved_docs:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p!")
                return {
                    "status": "no_results",
                    "question": question,
                    "answer": "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p v·ªõi c√¢u h·ªèi c·ªßa b·∫°n.",
                    "retrieved_docs": []
                }
            
            logger.info(f"‚úÖ T√¨m th·∫•y {len(retrieved_docs)} documents:")
            for doc in retrieved_docs:
                logger.info(f"   - {doc['metadata']['source']} (Trang {doc['metadata']['page']}) - Sim: {doc['similarity']}")
            
            # 3. X√¢y d·ª±ng context
            context = self._build_context(retrieved_docs)
            
            # 4. X√¢y d·ª±ng prompt
            prompt = self._build_prompt(context, question)
            logger.info(f"üìù Prompt length: {len(prompt)} chars")
            
            # 5. G·ªçi Gemini
            logger.info("ü§ñ G·ªçi Gemini ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi...")
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=GEMINI_TEMPERATURE,
                    max_output_tokens=GEMINI_MAX_TOKENS
                )
            )
            
            answer = response.text
            # Lo·∫°i b·ªè th√¥ng tin tr√≠ch d·∫´n d·∫°ng (file.pdf - Trang X) trong c√¢u tr·∫£ l·ªùi
            # Lo·∫°i b·ªè (file - Trang X) ho·∫∑c (file.pdf - Trang X)
            answer = re.sub(r'\s*\([^)]*-\s*Trang\s*\d+\)', '', answer)
            answer = re.sub(r'  +', ' ', answer).strip()  # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng th·ª´a
            logger.info("‚úÖ Sinh c√¢u tr·∫£ l·ªùi th√†nh c√¥ng\n")
            
            return {
                "status": "success",
                "question": question,
                "answer": answer,
                "retrieved_docs": retrieved_docs,
                "num_results": len(retrieved_docs)
            }
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói trong Q&A chain: {str(e)}")
            return {
                "status": "error",
                "question": question,
                "error": str(e)
            }
    
    def interactive_chat(self):
        """Interactive chatbot mode"""
        logger.info("\n" + "="*60)
        logger.info("üí¨ CH·∫æ ƒê·ªò T∆Ø∆†NG T√ÅC")
        logger.info("(Nh·∫≠p 'exit' ƒë·ªÉ tho√°t)")
        logger.info("="*60 + "\n")
        
        while True:
            try:
                question = input("üë§ B·∫°n: ").strip()
                
                if question.lower() == 'exit':
                    logger.info("üëã T·∫°m bi·ªát!")
                    break
                
                if not question:
                    continue
                
                result = self.query(question)
                
                print("\n" + "="*60)
                print("ü§ñ Chatbot:")
                print("="*60)
                print(result["answer"])
                print("\n" + "-"*60)
                print(f"üìä S·ªë t√†i li·ªáu t√¨m ƒë∆∞·ª£c: {result.get('num_results', 0)}")
                
                if result.get("retrieved_docs"):
                    print("\nüìö Ngu·ªìn tham kh·∫£o:")
                    for doc in result["retrieved_docs"]:
                        print(f"  ‚Ä¢ {doc['metadata']['source']} - Trang {doc['metadata']['page']} (T∆∞∆°ng t·ª±: {doc['similarity']})")
                
                print("="*60 + "\n")
            
            except KeyboardInterrupt:
                logger.info("\nüëã T·∫°m bi·ªát!")
                break
            except Exception as e:
                logger.error(f"‚ùå L·ªói: {str(e)}\n")
